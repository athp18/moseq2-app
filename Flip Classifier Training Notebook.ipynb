{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Label-Correctly-Oriented-Frame-Ranges\" data-toc-modified-id=\"Label-Correctly-Oriented-Frame-Ranges-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Label Correctly Oriented Frame Ranges</a></span><ul class=\"toc-item\"><li><span><a href=\"#Widget-Guide\" data-toc-modified-id=\"Widget-Guide-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Widget Guide</a></span></li><li><span><a href=\"#Instructions\" data-toc-modified-id=\"Instructions-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Instructions</a></span></li></ul></li><li><span><a href=\"#Prepare-Train-Test-Datasets\" data-toc-modified-id=\"Prepare-Train-Test-Datasets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prepare Train-Test Datasets</a></span></li><li><span><a href=\"#Fit-and-Evaluate-the-Flip-Classifier-Model\" data-toc-modified-id=\"Fit-and-Evaluate-the-Flip-Classifier-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Fit and Evaluate the Flip Classifier Model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Flip Classifier Training Notebook</h1></center>\n",
    "\n",
    "Flip classifiers are RandomForestClassifier models that MoSeq2-Extract uses to ensure that the mouse is always extracted facing east. This notebook is a streamlined utility and guide for preparing data and training a model that handles your specific data acquisition use case.\n",
    "\n",
    "To use this notebook, you must first extract some data using MoSeq2-Extract to use as training data for the flip classifier model. 100K frames is optimal for training the flip classifier. \n",
    "\n",
    "This is can be an iterative process if your data contains large amounts of flips throughout the extractions. On your first iteration, it is acceptable to extract the data without a flip-classifier. Each iteration of re-extracting the data (with your latest model) and training a new model will yield higher model accuracy.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=11Hsw5A3mjz5hQPBhr_dxhzE4pNzTsY4T\">\n",
    "\n",
    "## Label Correctly Oriented Frame Ranges\n",
    "\n",
    "Use this interactive tool to build your training dataset for the flip classifier model. You will select the frame ranges where the rodent is facing east, these ranges will be used to build your training set.\n",
    "\n",
    "### Widget Guide\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1YDfsPsOonD-8VlYZACcGrasw81zhkY8s\">\n",
    "\n",
    "### Instructions\n",
    "- First, use the Session Selector (1) to choose a session to label frames from.\n",
    "- Use the Slider (3) to select a frame index to preview.\n",
    "- To include a frame range in the \"correct range list\":\n",
    "   1. On the starting index, click the \"Start Range\" Button (4). This will start the frame range inclusion.\n",
    "   2. Increase the slider to the desired end index, and click the \"End Range\" Button (4) to add it to the included range.\n",
    "      - The slider minimum will be increased to 1 + the last stopping index.\n",
    "      - The selected frame range will appear in the box (6) next to the image preview (2).\n",
    "      - When the indicator (5) turns green, you are ready to continue onto the next cells.\n",
    "   3. Once all of your correct frame ranges are selected, click the \"Clear Output\" (7) button and continue to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from moseq2_app.main import flip_classifier_tool\n",
    "\n",
    "input_dir = './'\n",
    "model_path = './flip-classifier-xx-1.pkl' ## e.g. ./flip-classifier-azure-ephys.pkl\n",
    "\n",
    "max_frames = 1e5 # max number of frames to use (performance anecdotally saturates around 1e5)\n",
    "tail_filter_iters = 1 # number of tail filter iterations\n",
    "space_filter_size = 3 # size of the spatial median blur filter kernel size\n",
    "\n",
    "FF = flip_classifier_tool(input_dir=input_dir,\n",
    "                          output_file=model_path,\n",
    "                          max_frames=max_frames,\n",
    "                          tail_filter_iters=tail_filter_iters,\n",
    "                          space_filter_size=space_filter_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train-Test Datasets\n",
    "\n",
    "Split your dataset into a train/test X and y sets. \n",
    "\n",
    "Select a percent split for the test set such that you can accurately evaluate the model accuracy in the next following step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 20 # percent split\n",
    "\n",
    "FF.prepare_datasets(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Evaluate the Flip Classifier Model\n",
    "\n",
    "The following cell will train the model with the split data, determine the flip classifier's accuracy, then saves the model to your desired output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "max_depth = 6\n",
    "n_jobs = 4\n",
    "verbose = 0 # levels of verbosity: [0, 1, 2]\n",
    "\n",
    "FF.train_and_evaluate_model(n_estimators=n_estimators,\n",
    "                            n_jobs=n_jobs,\n",
    "                            max_depth=max_depth,\n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}