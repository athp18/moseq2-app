{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import All Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Syllable Statistics Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "from moseq2_viz.util import parse_index\n",
    "from moseq2_viz.viz import plot_syll_stats_with_sem\n",
    "from moseq2_viz.scalars.util import scalars_to_dataframe\n",
    "from moseq2_viz.model.util import (compute_behavioral_statistics, \n",
    "                                   sort_syllables_by_stat, get_syllable_usages,\n",
    "                                   compute_syllable_explained_variance,\n",
    "                                   sort_syllables_by_stat_difference)\n",
    "\n",
    "# Behavioral Distance Dependencies\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from moseq2_viz.model.dist import get_behavioral_distance\n",
    "\n",
    "# Transition Matrices Compute/Graphing Dependencies\n",
    "from moseq2_viz.model.util import parse_model_results, relabel_by_usage\n",
    "from moseq2_viz.model.trans_graph import get_trans_graph_groups, get_group_trans_mats, graph_transition_matrix\n",
    "\n",
    "# Hypothesis Testing Dependencies\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths to Model and Index Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = './moseq2-index.yaml'\n",
    "model_path = './saline-amphetamine/model.p'\n",
    "_, sorted_index = parse_index(index_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Number Of Syllables that Explain 99% of the Data's Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = parse_model_results(model_path)\n",
    "max_syllable = compute_syllable_explained_variance(model_data, n_explained=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Syllable Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sorted_index = parse_index(index_path)\n",
    "\n",
    "# compute session scalar data\n",
    "scalar_df = scalars_to_dataframe(sorted_index, model_path=model_path)\n",
    "\n",
    "# compute syllable usage and scalar statistics\n",
    "df = compute_behavioral_statistics(scalar_df, count='usage', groupby=['group', 'uuid'], usage_normalization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Scalar Means (By Group) For Each Syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = 'usage'\n",
    "\n",
    "unique_groups = df.group.unique()\n",
    "\n",
    "plot_syll_stats_with_sem(df, \n",
    "                         stat='usage',\n",
    "                         ordering='stat',\n",
    "                         max_sylls=max_syllable,\n",
    "                         groups=unique_groups,\n",
    "                         ctrl_group=None,\n",
    "                         exp_group=None,\n",
    "                         colors=None,\n",
    "                         join=True,\n",
    "                         figsize=(15,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Mean Statistics Sorted By Group Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistic to plot\n",
    "stat = 'usage'\n",
    "\n",
    "# groups to get difference\n",
    "group1 = 'Saline'\n",
    "group2 = 'Amphetamine'\n",
    "\n",
    "unique_groups = df.group.unique()\n",
    "\n",
    "plot_syll_stats_with_sem(df, \n",
    "                         stat='usage', # choose any of the df columns\n",
    "                         ordering='diff',\n",
    "                         max_sylls=max_syllable,\n",
    "                         groups=unique_groups,\n",
    "                         ctrl_group=group1,\n",
    "                         exp_group=group2,\n",
    "                         colors=None,\n",
    "                         join=True,\n",
    "                         figsize=(15,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Scalar Means (By Session) For Each Syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# you may switch 'uuid' with 'SessionName' or 'SubjectName' if they are all unique\n",
    "session_mean_df = df.groupby(['syllable', 'uuid']).mean() \n",
    "\n",
    "stat = 'usage'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "session_mean_df[stat].unstack().plot(style='o-', ax=ax, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Syllable Distance Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Pairwise distances\n",
    "X = get_behavioral_distance(sorted_index,\n",
    "                            model_path,\n",
    "                            max_syllable=max_syllable,\n",
    "                            distances=['ar[init]'])['ar[init]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Syllable Distance Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "\n",
    "# Compute linkage matrix with respect to a selected precomputed metric\n",
    "Z = linkage(np.nan_to_num(X), 'complete')\n",
    "results = dendrogram(Z, distance_sort=False, get_leaves=True, ax=ax, color_threshold=0)\n",
    "similarity_ordering = results['leaves']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Syllable Transition Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your model\n",
    "model_data = parse_model_results(model_path)\n",
    "\n",
    "# set maximum syllables to include\n",
    "max_syllable = 40\n",
    "\n",
    "# select a transition matrix normalization method\n",
    "normalize = 'bigram' # other options: 'columns', 'rows'\n",
    "\n",
    "# Get labels and relabel them by usage sorting\n",
    "labels = model_data['labels']\n",
    "labels = relabel_by_usage(labels, count='usage')[0]\n",
    "\n",
    "# Get modeled session uuids to compute group-mean transition graph for\n",
    "group, label_group, _ = get_trans_graph_groups(model_data, sorted_index)\n",
    "\n",
    "# compute transition matrices and usages for each group\n",
    "trans_mats, usages = get_group_trans_mats(labels, label_group, group, max_syllable, normalize=normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Computed Transition Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _, _ = graph_transition_matrix(trans_mats,\n",
    "                                    layout='spring', # or: 'circular', 'spectral'\n",
    "                                    usages=usages,\n",
    "                                    groups=group,\n",
    "                                    arrows=True,\n",
    "                                    headless=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Mean Grouped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_mean_df(df, group, stat, max_syllable):\n",
    "    \n",
    "    selected_group =  df['group'] == group\n",
    "    df = df[selected_group]\n",
    "    \n",
    "    uuids = df.uuid.unique()\n",
    "    \n",
    "    group_stat = np.zeros((len(uuids), max_syllable))\n",
    "    for i, uuid in enumerate(uuids):\n",
    "        group_stat[i] = df[df['uuid'] == uuid][stat][:max_syllable]\n",
    "    \n",
    "    \n",
    "    return group_stat\n",
    "    \n",
    "\n",
    "# select statistic to compute\n",
    "statistic = 'usage'\n",
    "\n",
    "# select groups to compare\n",
    "group1 = 'Saline'\n",
    "group2 = 'Amphetamine'\n",
    "\n",
    "# get separated group variables\n",
    "group1_stat = get_session_mean_df(df, group1, statistic, max_syllable)\n",
    "group2_stat = get_session_mean_df(df, group2, statistic, max_syllable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_group(lst, rng):\n",
    "    return list(rng.choice(len(lst),len(lst),replace=True))\n",
    "\n",
    "def bootstrap_me(usages, iters=10000):\n",
    "    bootstrap_mean_usages = []\n",
    "    for i in range(iters):\n",
    "        rng = np.random.RandomState(seed=i)\n",
    "        temp = []\n",
    "        boot_mice = bootstrap_group(usages, rng)\n",
    "        for mouse in boot_mice:\n",
    "            temp.append(usages[mouse])\n",
    "        temp = np.asarray(temp)\n",
    "        bootstrap_mean_usages.append(np.nanmean(temp,axis=0))\n",
    "        \n",
    "    return bootstrap_mean_usages\n",
    "\n",
    "group1_boot = np.array(bootstrap_me(group1_stat))\n",
    "group2_boot = np.array(bootstrap_me(group2_stat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Z-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ztest(d1, d2, mu1=None, mu2=None):\n",
    "    mu1 = d1.mean() if mu1 is None else mu1\n",
    "    mu2 = d2.mean() if mu2 is None else mu2\n",
    "    std1, std2 = d1.std(), d2.std()\n",
    "\n",
    "    std = np.sqrt(std1**2 + std2**2)\n",
    "    return np.minimum(1.,2*stats.norm.cdf(-np.abs(mu1 - mu2)/std))\n",
    "\n",
    "# do a ztest on the bootstrap distributions of your 2 conditions\n",
    "pvals_ztest_boots = np.array([ztest(group1_boot[:,i], group2_boot[:,i]) for i in range(group1_boot.shape[1])])\n",
    "\n",
    "np.array(range(len(pvals_ztest_boots)))[pvals_ztest_boots < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Comparisons Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant syllables (relabeled by time used)\n",
    "np.where(multipletests(pvals_ztest_boots, alpha=0.10, method='fdr_bh')[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st, p = stats.ttest_ind(group1_stat, group2_stat)\n",
    "\n",
    "np.array(range(len(p)))[p < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Comparisons Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant syllables (relabeled by time used)\n",
    "np.where(multipletests(p, alpha=0.10, method='fdr_bh')[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
